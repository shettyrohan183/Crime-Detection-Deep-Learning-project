{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7156cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from time import time\n",
    "import cv2\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials , firestore ,db\n",
    "from pickle import load\n",
    "from tensorflow.keras.models import load_model\n",
    "cred = credentials.Certificate(\"data.json\")\n",
    "import datetime\n",
    "\n",
    "firebase_admin.initialize_app(cred,{\n",
    "'databaseURL': databaseurl\n",
    "})\n",
    "import tensorflow\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models  import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, Activation, LeakyReLU, Add, Multiply\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# from keras.layers.core import Lambda\n",
    "from tensorflow.keras.layers import Lambda\n",
    "# from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c89476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "names = []\n",
    "s_dict = {}\n",
    "cam_to_watch = []\n",
    "def some_magic(string):\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "    \n",
    "    name = string\n",
    "    class DataGenerator(Sequence):\n",
    "        \"\"\"Data Generator inherited from keras.utils.Sequence\n",
    "        Args: \n",
    "            directory: the path of data set, and each sub-folder will be assigned to one class\n",
    "            batch_size: the number of data points in each batch\n",
    "            shuffle: whether to shuffle the data per epoch\n",
    "        Note:\n",
    "            If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
    "        \"\"\"\n",
    "        def __init__(self, directory, batch_size=1, shuffle=False, data_augmentation=True):\n",
    "            # Initialize the params\n",
    "            self.batch_size = batch_size\n",
    "            self.directory = directory\n",
    "            self.shuffle = shuffle\n",
    "            self.data_aug = data_augmentation\n",
    "            # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
    "            self.X_path, self.Y_dict = self.search_data() \n",
    "            # Print basic statistics information\n",
    "            self.print_stats()\n",
    "            return None\n",
    "        def search_data(self):\n",
    "            X_path = []\n",
    "            Y_dict = {}\n",
    "            # list all kinds of sub-folders\n",
    "            self.dirs = sorted(os.listdir(self.directory))\n",
    "            one_hots = utils.to_categorical(range(len(self.dirs)))\n",
    "            for i,folder in enumerate(self.dirs):\n",
    "                folder_path = os.path.join(self.directory,folder)\n",
    "                for file in os.listdir(folder_path):\n",
    "#                     print(file)\n",
    "                    file_path = os.path.join(folder_path,file)\n",
    "                    # append the each file path, and keep its label  \n",
    "                    X_path.append(file_path)\n",
    "                    Y_dict[file_path] = one_hots[i]\n",
    "            return X_path, Y_dict\n",
    "    \n",
    "        def print_stats(self):\n",
    "            # calculate basic information\n",
    "            self.n_files = len(self.X_path)\n",
    "            self.n_classes = len(self.dirs)\n",
    "            self.indexes = np.arange(len(self.X_path))\n",
    "            np.random.shuffle(self.indexes)\n",
    "            # Output states\n",
    "            print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
    "            for i,label in enumerate(self.dirs):\n",
    "                print('%10s : '%(label),i)\n",
    "            return None\n",
    "        def __len__(self):\n",
    "            # calculate the iterations of each epoch\n",
    "            steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
    "            return int(steps_per_epoch)\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"Get the data of each batch\n",
    "            \"\"\"\n",
    "            # get the indexs of each batch\n",
    "            batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "            # using batch_indexs to get path of current batch\n",
    "            batch_path = [self.X_path[k] for k in batch_indexs]\n",
    "            # get batch data\n",
    "            batch_x, batch_y = self.data_generation(batch_path)\n",
    "            return batch_x, batch_y\n",
    "\n",
    "        def on_epoch_end(self):\n",
    "            # shuffle the data at each end of epoch\n",
    "            if self.shuffle == True:\n",
    "                np.random.shuffle(self.indexes)\n",
    "\n",
    "        def data_generation(self, batch_path):\n",
    "            # load data into memory, you can change the np.load to any method you want\n",
    "            batch_x = [self.load_data(x) for x in batch_path]\n",
    "            batch_y = [self.Y_dict[x] for x in batch_path]\n",
    "            # transfer the data format and take one-hot coding for labels\n",
    "            batch_x = np.array(batch_x)\n",
    "            batch_y = np.array(batch_y)\n",
    "            return batch_x, batch_y\n",
    "    \n",
    "        def normalize(self, data):\n",
    "            mean = np.mean(data)\n",
    "            std = np.std(data)\n",
    "            return (data-mean) / std\n",
    "    \n",
    "        def random_flip(self, video, prob):\n",
    "            s = np.random.rand()\n",
    "            if s < prob:\n",
    "                video = np.flip(m=video, axis=2)\n",
    "            return video    \n",
    "    \n",
    "        def uniform_sampling(self, video, target_frames=64):\n",
    "            # get total frames of input video and calculate sampling interval \n",
    "            len_frames = int(len(video))\n",
    "            interval = int(np.ceil(len_frames/target_frames))\n",
    "            # init empty list for sampled video and \n",
    "            sampled_video = []\n",
    "            for i in range(0,len_frames,interval):\n",
    "                sampled_video.append(video[i])     \n",
    "            # calculate numer of padded frames and fix it \n",
    "            num_pad = target_frames - len(sampled_video)\n",
    "            padding = []\n",
    "            if num_pad>0:\n",
    "                for i in range(-num_pad,0):\n",
    "                    try: \n",
    "                        padding.append(video[i])\n",
    "                    except:\n",
    "                        padding.append(video[0])\n",
    "                sampled_video += padding     \n",
    "            # get sampled video\n",
    "            return np.array(sampled_video, dtype=np.float32)\n",
    "    \n",
    "        def random_clip(self, video, target_frames=64):\n",
    "            start_point = np.random.randint(len(video)-target_frames)\n",
    "            return video[start_point:start_point+target_frames]\n",
    "    \n",
    "        def dynamic_crop(self, video):\n",
    "            # extract layer of optical flow from video\n",
    "            opt_flows = video[...,3]\n",
    "            # sum of optical flow magnitude of individual frame\n",
    "            magnitude = np.sum(opt_flows, axis=0)\n",
    "            # filter slight noise by threshold \n",
    "            thresh = np.mean(magnitude)\n",
    "            magnitude[magnitude<thresh] = 0\n",
    "            # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
    "            x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
    "            y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
    "            # normalize PDF of x and y so that the sum of probs = 1\n",
    "            x_pdf /= np.sum(x_pdf)\n",
    "            y_pdf /= np.sum(y_pdf)\n",
    "            # randomly choose some candidates for x and y \n",
    "            x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
    "            y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
    "            # get the mean of x and y coordinates for better robustness\n",
    "            x = int(np.mean(x_points))\n",
    "            y = int(np.mean(y_points))\n",
    "            # avoid to beyond boundaries of array\n",
    "            x = max(56,min(x,167))\n",
    "            y = max(56,min(y,167))\n",
    "            # get cropped video \n",
    "            return video[:,x-56:x+56,y-56:y+56,:] \n",
    "\n",
    "        def color_jitter(self,video):\n",
    "            # range of s-component: 0-1\n",
    "            # range of v component: 0-255\n",
    "            s_jitter = np.random.uniform(-0.2,0.2)\n",
    "            v_jitter = np.random.uniform(-30,30)\n",
    "            for i in range(len(video)):\n",
    "                hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
    "                s = hsv[...,1] + s_jitter\n",
    "                v = hsv[...,2] + v_jitter\n",
    "                s[s<0] = 0\n",
    "                s[s>1] = 1\n",
    "                v[v<0] = 0\n",
    "                v[v>255] = 255\n",
    "                hsv[...,1] = s\n",
    "                hsv[...,2] = v\n",
    "                video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "            return video\n",
    "\n",
    "        def load_data(self, path):\n",
    "            # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
    "            data = np.load(path, mmap_mode='r',allow_pickle=True)\n",
    "            data = np.float32(data)\n",
    "            # sampling 64 frames uniformly from the entire video\n",
    "            data = self.uniform_sampling(video=data, target_frames=64)\n",
    "            # whether to utilize the data augmentation\n",
    "            if  self.data_aug:\n",
    "                data[...,:3] = self.color_jitter(data[...,:3])\n",
    "                data = self.random_flip(data, prob=0.5)\n",
    "            # normalize rgb images and optical flows, respectively\n",
    "            data[...,:3] = self.normalize(data[...,:3])\n",
    "            data[...,3:] = self.normalize(data[...,3:])\n",
    "            return data\n",
    "\n",
    "    def Video2Npy(file_path, resize=(224,224)):\n",
    "        \"\"\"Load video and tansfer it into .npy format\n",
    "        Args:\n",
    "            file_path: the path of video file\n",
    "            resize: the target resolution of output video\n",
    "        Returns:\n",
    "            frames: gray-scale video\n",
    "            flows: magnitude video of optical flows \n",
    "        \"\"\"\n",
    "        # Load video\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        # Get number of frames\n",
    "        len_frames = int(cap.get(7))\n",
    "        # Extract frames from video\n",
    "        try:\n",
    "            frames = []\n",
    "            for i in range(len_frames-1):\n",
    "                _, frame = cap.read()\n",
    "                frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = np.reshape(frame, (224,224,3))\n",
    "                frames.append(frame)   \n",
    "        except:\n",
    "            print(\"Error: \", file_path, len_frames,i)\n",
    "        finally:\n",
    "            frames = np.array(frames)\n",
    "            cap.release()\n",
    "\n",
    "        # Get the optical flow of video\n",
    "        flows = getOpticalFlow(frames)\n",
    "\n",
    "        result = np.zeros((len(flows),224,224,5))\n",
    "        result[...,:3] = frames\n",
    "        result[...,3:] = flows\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def getOpticalFlow(video):\n",
    "        \"\"\"Calculate dense optical flow of input video\n",
    "        Args:\n",
    "            video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
    "        Returns:\n",
    "            flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
    "            flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
    "        \"\"\"\n",
    "        # initialize the list of optical flows\n",
    "        gray_video = []\n",
    "        for i in range(len(video)):\n",
    "            img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
    "            gray_video.append(np.reshape(img,(224,224,1)))\n",
    "\n",
    "        flows = []\n",
    "        for i in range(0,len(video)-1):\n",
    "            # calculate optical flow between each pair of frames\n",
    "            flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "            # subtract the mean in order to eliminate the movement of camera\n",
    "            flow[..., 0] -= np.mean(flow[..., 0])\n",
    "            flow[..., 1] -= np.mean(flow[..., 1])\n",
    "            # normalize each component in optical flow\n",
    "            flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
    "            flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
    "            # Add into list \n",
    "            flows.append(flow)\n",
    "\n",
    "        # Padding the last frame as empty array\n",
    "        flows.append(np.zeros((224,224,2)))\n",
    "\n",
    "        return np.array(flows, dtype=np.float32)\n",
    "\n",
    "\n",
    "    def Save2Npy(file_dir, save_dir):\n",
    "        \"\"\"Transfer all the videos and save them into specified directory\n",
    "        Args:\n",
    "            file_dir: source folder of target videos\n",
    "            save_dir: destination folder of output .npy files\n",
    "        \"\"\"\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        # List the files\n",
    "        videos = os.listdir(file_dir)\n",
    "        for v in tqdm(videos):\n",
    "            # Split video name\n",
    "            video_name = v.split('.')[0]\n",
    "            # Get src \n",
    "            video_path = os.path.join(file_dir, v)\n",
    "            # Get dest \n",
    "            save_path = os.path.join(save_dir, video_name+'.npy') \n",
    "            # Load and preprocess video\n",
    "            data = Video2Npy(file_path=video_path, resize=(224,224))\n",
    "            data = np.uint8(data)\n",
    "            # Save as .npy file\n",
    "            np.save(save_path, data)\n",
    "\n",
    "        return None\n",
    "        \n",
    "        \n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    if string==\"web\":\n",
    "        import time\n",
    "\n",
    "        # The duration in seconds of the video captured\n",
    "        for i in range(2):\n",
    "            capture_duration = 10\n",
    "\n",
    "            cap = cv2.VideoCapture(0)\n",
    "\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            out = cv2.VideoWriter(r'E:\\go_ai\\last-crime\\ourliv\\13-0308_77-5642'+str(i)+'.avi',fourcc, 20.0, (640,480))\n",
    "\n",
    "            start_time = time.time()\n",
    "            while( int(time.time() - start_time) < capture_duration ):\n",
    "                ret, frame = cap.read()\n",
    "                if ret==True:\n",
    "                    frame = cv2.flip(frame,0)\n",
    "                    out.write(frame)\n",
    "                    cv2.imshow('frame',frame)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "        source_path = r'E:\\go_ai\\last-crime\\ourliv'\n",
    "        target_path = r'E:\\go_ai\\last-crime\\data\\our\\vid'\n",
    "        Save2Npy(source_path, target_path)\n",
    "        onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') if isfile(join(r'E:\\go_ai\\last-crime\\data\\our\\vid', f))]\n",
    "        list = os.listdir(r'E:\\go_ai\\last-crime\\data\\our\\vid') # dir is your directory path\n",
    "        number_files = len(list)\n",
    "#         print(number_files)\n",
    "        val_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\our',\n",
    "                              batch_size=1, \n",
    "                              data_augmentation=False)\n",
    "    if string==\"local\":\n",
    "        source_path = r'E:\\go_ai\\last-crime\\video'\n",
    "        target_path = r'E:\\go_ai\\last-crime\\data\\sam\\vi'\n",
    "        Save2Npy(source_path, target_path)\n",
    "        onlyfiles = [f for f in listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') if isfile(join(r'E:\\go_ai\\last-crime\\data\\sam\\vi', f))]\n",
    "        list = os.listdir(r'E:\\go_ai\\last-crime\\data\\sam\\vi') # dir is your directory path\n",
    "        number_files = len(list)\n",
    "#         print(number_files)\n",
    "        val_generator = DataGenerator(directory=r'E:\\go_ai\\last-crime\\data\\sam',\n",
    "                              batch_size=1, \n",
    "                              data_augmentation=False)\n",
    "        \n",
    "    def addData(lat_lang,time):\n",
    "        ref = db.reference(\"/\")\n",
    "        res=ref.get(\"/\")\n",
    "#         print(res[0])\n",
    "        res[0][lat_lang]=time\n",
    "        res=ref.set(res[0])\n",
    "        \n",
    "    inds = getattr(val_generator, \"indexes\")\n",
    "    print(inds)\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    \n",
    "#     Give the path for video files not numpy\n",
    "    if name==\"local\":\n",
    "        onlyfiles1 = [f for f in listdir(r'E:\\go_ai\\last-crime\\video') if isfile(join(r'E:\\go_ai\\last-crime\\video', f))]\n",
    "    elif name==\"web\":\n",
    "          onlyfiles1 = [f for f in listdir( r'E:\\go_ai\\last-crime\\ourliv') if isfile(join(r'E:\\go_ai\\last-crime\\ourliv', f))]\n",
    "        \n",
    "    inds_lis = inds.tolist()\n",
    "    for i in inds_lis:\n",
    "        s_dict[i+1] = onlyfiles[i]\n",
    "        \n",
    "    \n",
    "#     new_d = {}\n",
    "#     j = 0\n",
    "#     for i in inds_lis:\n",
    "#         val = s_dict.get(i)\n",
    "#         new_d[val] = pred(j)\n",
    "#         j= j+1\n",
    "#     j=0\n",
    "#     print(new_d)\n",
    "    \n",
    "    \n",
    "    hist = load_model('keras_model.h5')\n",
    "#     print(\"val\",val_generator)\n",
    "    pred = hist.predict(val_generator)\n",
    "    \n",
    "    \n",
    "    print(pred)\n",
    "    newd = {}\n",
    "    \n",
    "    newd = {}\n",
    "    i = 0\n",
    "    for k in s_dict:\n",
    "        v = s_dict.get(k)\n",
    "        print(v)\n",
    "        newd[s_dict.get(k)] = pred[i]\n",
    "        i = i+1\n",
    "        \n",
    "    i=0\n",
    "    from pprint import pprint\n",
    "    pprint(newd)\n",
    "    \n",
    "    if name==\"local\":\n",
    "        files = glob.glob(r'E:\\go_ai\\last-crime\\data\\sam\\vi\\*')\n",
    "    else:\n",
    "        files = glob.glob(r'E:\\go_ai\\last-crime\\data\\our\\vid\\*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "        \n",
    "    \n",
    "    \n",
    "      \n",
    "    \n",
    "    s=[]\n",
    "    for i in range(number_files):\n",
    "        if pred[i][0] > 0.65:\n",
    "            e = datetime.datetime.now()\n",
    "            date_time = e.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "#             print(\"date and time:\", date_time)\n",
    "            to_get = inds_lis[i]\n",
    "#             to_get = to_get + 1\n",
    "            name = s_dict.get(to_get)\n",
    "            if(string==\"web\"):\n",
    "                name = onlyfiles[i].replace(\".npy\",\"\")\n",
    "            else:\n",
    "                name = onlyfiles[i].replace(\".npy\",\"\")\n",
    "            s.append(name+\" crime has been detected at \"+str(e))\n",
    "            addData(name,date_time)\n",
    "            print(\"\\n\")\n",
    "            cam_to_watch.append(name)\n",
    "    print(\"Watch these camera\")\n",
    "    print(cam_to_watch)\n",
    "#     from pprint import pprint\n",
    "#     pprint(s_dict)\n",
    "#     pprint(cam_to_watch)\n",
    "#     return s\n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c87b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [01:03<00:00,  9.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 files belonging to 1 classes.\n",
      "        vi :  0\n",
      "[0 1 3 5 2 6 4]\n",
      "7/7 [==============================] - 23s 3s/step\n",
      "[[0.77555305 0.22444694]\n",
      " [0.8497123  0.1502877 ]\n",
      " [0.8709945  0.1290055 ]\n",
      " [0.16322285 0.83677715]\n",
      " [0.8520385  0.14796145]\n",
      " [0.91461027 0.08538967]\n",
      " [0.05960685 0.94039315]]\n",
      "12-8413_77-6618.npy\n",
      "12-8831_77-6164.npy\n",
      "12-9862_77-4988.npy\n",
      "12-9869_77-6723.npy\n",
      "12-9117_77-5369.npy\n",
      "13-0334_77-4900.npy\n",
      "12-9866_77-6513.npy\n",
      "{'12-8413_77-6618.npy': array([0.77555305, 0.22444694], dtype=float32),\n",
      " '12-8831_77-6164.npy': array([0.8497123, 0.1502877], dtype=float32),\n",
      " '12-9117_77-5369.npy': array([0.8520385 , 0.14796145], dtype=float32),\n",
      " '12-9862_77-4988.npy': array([0.8709945, 0.1290055], dtype=float32),\n",
      " '12-9866_77-6513.npy': array([0.05960685, 0.94039315], dtype=float32),\n",
      " '12-9869_77-6723.npy': array([0.16322285, 0.83677715], dtype=float32),\n",
      " '13-0334_77-4900.npy': array([0.91461027, 0.08538967], dtype=float32)}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Watch these camera\n",
      "['12-8413_77-6618', '12-8831_77-6164', '12-9117_77-5369', '12-9866_77-6513', '12-9869_77-6723']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    some_magic(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2379f24b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:14<00:00,  7.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 files belonging to 1 classes.\n",
      "       vid :  0\n",
      "[1 0]\n",
      "2/2 [==============================] - 5s 2s/step\n",
      "[[0.3302087  0.6697913 ]\n",
      " [0.16115928 0.83884066]]\n",
      "13-0308_77-56421.npy\n",
      "13-0308_77-56420.npy\n",
      "{'13-0308_77-56420.npy': array([0.16115928, 0.83884066], dtype=float32),\n",
      " '13-0308_77-56421.npy': array([0.3302087, 0.6697913], dtype=float32)}\n",
      "Watch these camera\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     some_magic(\"web\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "266ab895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12-8413_77-6618',\n",
      " '12-8831_77-6164',\n",
      " '12-9117_77-5369',\n",
      " '12-9866_77-6513',\n",
      " '12-9869_77-6723']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cam_to_watch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "483be9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 000001FC9F995830>\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "1\n",
      "saving\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image,ImageTk\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "from pygrabber.dshow_graph import FilterGraph\n",
    "import face_recognition\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from os import listdir\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "# for i in cam_to_watch:\n",
    "SEQUENCE_LENGTH = 20\n",
    "#     name = r\"E:\\go_ai\\last-crime\\video\" + \"\\\\\"\n",
    "IMAGE_HEIGHT , IMAGE_WIDTH = 224, 224\n",
    "cap = cv2.VideoCapture(r'E:\\go_ai\\last-crime\\Fvideo\\12-8831_77-6164.avi')\n",
    "# print(i)\n",
    "#     cap = 'E:\\go_ai\\last-crime\\video\\12-8831_77-6164.avi'\n",
    "print(cap)\n",
    "\n",
    "frames_queue = deque(maxlen = 20)\n",
    "t1 = time.time()\n",
    "while True:\n",
    "    ok, frame = cap.read()\n",
    "    if not ok:\n",
    "        break\n",
    "    frame = cv2.flip(frame, 1)\n",
    "#         print(\"this while\")\n",
    "    resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "    normalized_frame = resized_frame / 255\n",
    "#         cv2.imwrite(os.path.join(os.getcwd()+'/savedImages',str(dt.datetime.now()).replace(\":\",\"_\")+\".jpg\"),normalized_frame)\n",
    "    frames_queue.append(normalized_frame)\n",
    "\n",
    "#     if len(frames_queue) == SEQUENCE_LENGTH:\n",
    "# #         predictions = model.predict(np.expand_dims(frames_queue, axis = 0))[0]\n",
    "#         fight.config(text =\"Abnormal: \"+ str(predictions[0]))\n",
    "#         NonFight.config(text =\"Normal: \"+ str(predictions[1]))\n",
    "\n",
    "    m = face_recognition.face_locations(frame)\n",
    "    print(len(m))\n",
    "    if len(m) > 0 :\n",
    "        for i in range(len(m)):\n",
    "            cv2.putText(frame, \"Face detected\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        # cv2.rectangle(frame,(m[i][3],m[i][0]),(m[i][1],m[i][2]),(0,255,0),2)\n",
    "            if (int(time.time()) - int(t1)) % 1 == 0:\n",
    "                cv2.putText(frame, \"Saving\", (300, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                # cv2.rectangle(frame,(m[i][3],m[i][0]),(m[i][1],m[i][2]),(255,0,0),2)\n",
    "                print(\"saving\")\n",
    "                cv2.imwrite((r\"E:\\go_ai\\last-crime\\savedImages\\\\\" +str(dt.datetime.now()).replace(\":\",\"_\")+\".jpg\"),frame)\n",
    "                if m==1:\n",
    "                    break\n",
    "            # temp = frame[m[i][0]:m[i][2],m[i][3]:m[i][1]]     \n",
    "                t1 = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f02825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
